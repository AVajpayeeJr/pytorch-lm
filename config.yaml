data:
    word_min_count: 2
    vocab_size: 100000
    num_train_sentences: 200000
    num_valid_sentences: 5000
    num_test_sentences: 5000
    min_sentence_len: 3
    max_sentence_len: 50
model:
    embedding:
        type: word
        word:
            dim: 125
    encoder:
        type: GRU
        num_layers: 2
        hidden_size: 125
        dropout: 0.3
training:
    optimizer:
        name: adam
        lr: 0.001
    grad_clip: 5.0
    epochs: 15
    log_interval: 1
    batch_size: 32
arpa_conversion:
    rnn_ngram_context: 2
    ngram_pruning:
        2: 2000000
        3: 400000
    history_pruning:
        2: 50000
